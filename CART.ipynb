{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CART.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8eGEhhd4osR1QbCfJK4fi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Himabindugssn/Machine-Learning-Algorithms-/blob/main/CART.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJSsS_kzqYkK"
      },
      "source": [
        "## Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGZ7ysnSn0gC"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S5X1EcdqbqF"
      },
      "source": [
        "## Define a class, functions required to implement CART"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0dn4tuC-X4M"
      },
      "source": [
        "class DecisionTree(object):\n",
        "\n",
        "    def __init__(self, _max_depth, _min_splits):\n",
        "        self.max_depth = _max_depth\n",
        "        self.min_splits = _min_splits\n",
        "\n",
        "    def fit(self, _feature, _label):\n",
        "        \n",
        "        self.feature = _feature\n",
        "        self.label = _label\n",
        "        self.train_data = np.column_stack((self.feature,self.label))\n",
        "        self.build_tree()\n",
        "\n",
        "\n",
        "    def compute_gini_similarity(self, groups, class_labels):\n",
        "\n",
        "        #compute the gini index for the groups and class labels  \n",
        "        num_sample = sum([len(group) for group in groups])\n",
        "        gini_score = 0\n",
        "\n",
        "        for group in groups:\n",
        "            size = float(len(group))\n",
        "\n",
        "            if size == 0:\n",
        "                continue\n",
        "            score = 0.0\n",
        "            for label in class_labels:\n",
        "                porportion = (group[:,-1] == label).sum() / size\n",
        "                score += porportion * porportion\n",
        "            gini_score += (1.0 - score) * (size/num_sample)\n",
        "\n",
        "        return gini_score\n",
        "\n",
        "    def terminal_node(self, _group):\n",
        "\n",
        "        #helper function used to mark the leaf node in the tree based on the early stop condition or actual stop condition  \n",
        "        class_labels, count = np.unique(_group[:,-1], return_counts= True)\n",
        "        return class_labels[np.argmax(count)]\n",
        "\n",
        "    def split(self, index, val, data):\n",
        "    \n",
        "        data_left = np.array([]).reshape(0,self.train_data.shape[1])\n",
        "        data_right = np.array([]).reshape(0, self.train_data.shape[1])\n",
        "\n",
        "        for row in data:\n",
        "            if row[index] <= val :\n",
        "                data_left = np.vstack((data_left,row))\n",
        "\n",
        "            if row[index] > val:\n",
        "                data_right = np.vstack((data_right, row))\n",
        "\n",
        "        return data_left, data_right\n",
        "\n",
        "    def best_split(self, data):\n",
        "       \n",
        "        #using the gini score\n",
        "        class_labels = np.unique(data[:,-1])\n",
        "        best_index = 999\n",
        "        best_val = 999\n",
        "        best_score = 999\n",
        "        best_groups = None\n",
        "\n",
        "        for idx in range(data.shape[1]-1):\n",
        "            for row in data:\n",
        "                groups = self.split(idx, row[idx], data)\n",
        "                gini_score = self.compute_gini_similarity(groups,class_labels)\n",
        "\n",
        "                if gini_score < best_score:\n",
        "                    best_index = idx\n",
        "                    best_val = row[idx]\n",
        "                    best_score = gini_score\n",
        "                    best_groups = groups\n",
        "        result = {}\n",
        "        result['index'] = best_index\n",
        "        result['val'] = best_val\n",
        "        result['groups'] = best_groups\n",
        "        return result\n",
        "\n",
        "\n",
        "    def split_branch(self, node, depth):\n",
        "        \"\"\"\n",
        "        recursively split the data \n",
        "        check for early stop argument based on self.max_depth and self.min_splits\n",
        "        - check if left or right groups are empty is yess craete terminal node\n",
        "        - check if we have reached max_depth early stop condition if yes create terminal node\n",
        "        - Consider left node, check if the group is too small using min_split condition\n",
        "            - if yes create terminal node\n",
        "            - else continue to build the tree\n",
        "        - check right\n",
        "        \"\"\"\n",
        "        left_node , right_node = node['groups']\n",
        "        del(node['groups'])\n",
        "\n",
        "        if not isinstance(left_node,np.ndarray) or not isinstance(right_node,np.ndarray):\n",
        "            node['left'] = self.terminal_node(left_node + right_node)\n",
        "            node['right'] = self.terminal_node(left_node + right_node)\n",
        "            return\n",
        "\n",
        "        if depth >= self.max_depth:\n",
        "            node['left'] = self.terminal_node(left_node)\n",
        "            node['right'] = self.terminal_node(right_node)\n",
        "            return\n",
        "\n",
        "        if len(left_node) <= self.min_splits:\n",
        "            node['left'] = self.terminal_node(left_node)\n",
        "        else:\n",
        "            node['left'] = self.best_split(left_node)\n",
        "            self.split_branch(node['left'],depth + 1)\n",
        "\n",
        "\n",
        "        if len(right_node) <= self.min_splits:\n",
        "            node['right'] = self.terminal_node(right_node)\n",
        "        else:\n",
        "            node['right'] = self.best_split(right_node)\n",
        "            self.split_branch(node['right'],depth + 1)\n",
        "\n",
        "    def build_tree(self):\n",
        "        \"\"\"\n",
        "        build tree recursively with help of split_branch function\n",
        "         - Create a root node\n",
        "         - call recursive split_branch to build the complete tree\n",
        "        \"\"\"\n",
        "        self.root = self.best_split(self.train_data)\n",
        "        self.split_branch(self.root, 1)\n",
        "        return self.root\n",
        "\n",
        "    def _predict(self, node, row):\n",
        "\n",
        "        if row[node['index']] < node['val']:\n",
        "            if isinstance(node['left'], dict):\n",
        "                return self._predict(node['left'], row)\n",
        "            else:\n",
        "                return node['left']\n",
        "\n",
        "        else:\n",
        "            if isinstance(node['right'],dict):\n",
        "                return self._predict(node['right'],row)\n",
        "            else:\n",
        "                return node['right']\n",
        "\n",
        "    def predict(self, test_data):\n",
        "    \n",
        "        self.predicted_label = np.array([])\n",
        "        for idx in test_data:\n",
        "            self.predicted_label = np.append(self.predicted_label, self._predict(self.root,idx))\n",
        "\n",
        "        return self.predicted_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PHCYYBfoxiS"
      },
      "source": [
        "def accuracy(prediction, actual):\n",
        "    correct_count = 0\n",
        "    prediction_len = len(prediction)\n",
        "    for idx in range(prediction_len):\n",
        "        if int(prediction[idx]) == actual[idx]:\n",
        "            correct_count += 1\n",
        "    return correct_count/prediction_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwibHfuFo0GZ"
      },
      "source": [
        "def main():\n",
        "    iris = load_iris() #load dataset from sklearn\n",
        "    feature = iris.data[:,:2]\n",
        "    label = iris.target\n",
        "\n",
        "    # split the dataset into train and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(feature, label, random_state= 42)\n",
        "\n",
        "    # decision tree\n",
        "    decision_tree_model =  DecisionTree(_max_depth = 3, _min_splits = 40)\n",
        "    decision_tree_model.fit(X_train, y_train)\n",
        "    prediction  = decision_tree_model.predict(X_test)\n",
        "    \n",
        "    # decision tree from sk learn CART\n",
        "    sk_dt_model = DecisionTreeClassifier(max_depth= 3, min_samples_split= 40,criterion='gini')\n",
        "    sk_dt_model.fit(X_train, y_train)\n",
        "    sk_dt_prediction = sk_dt_model.predict(X_test)\n",
        "\n",
        "    #decision tree from sklearn ID3\n",
        "    sk_dt_model = DecisionTreeClassifier(max_depth= 3, min_samples_split= 40,criterion='entropy')\n",
        "    sk_dt_model.fit(X_train, y_train)\n",
        "    sk_dt_prediction = sk_dt_model.predict(X_test)\n",
        "\n",
        "    print(\"CART implemented accuracy : {0}\".format(accuracy(prediction, y_test)))\n",
        "    print(\"Sklearn CART accuracy : {0}\".format(accuracy(sk_dt_prediction, y_test)))\n",
        "    print(\"Sklearn ID3 accuracy : {0}\".format(accuracy(sk_dt_prediction, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGoa1y2iqijT"
      },
      "source": [
        "## Compare with sklearn built in methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiqIe7yZZEOo",
        "outputId": "324da6de-111d-4720-9538-2fa3ca8d2b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "if  __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CART implemented accuracy : 0.7368421052631579\n",
            "Sklearn CART accuracy : 0.6842105263157895\n",
            "Sklearn ID3 accuracy : 0.6842105263157895\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}